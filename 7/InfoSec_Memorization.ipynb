{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HsHGPWZBFtS"
      },
      "source": [
        "#Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHH8AofBE9Ic",
        "outputId": "0081728e-4b6e-4287-cb43-c060ef7ea75b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "  # mount your google drive to get permanent storage for your results\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "  RESULTS_PATH = \"/content/drive/MyDrive/infoseclab_ML/results\"\n",
        "except ModuleNotFoundError:\n",
        "  RESULTS_PATH = \"results\"\n",
        "\n",
        "!mkdir -p {RESULTS_PATH}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkfrTYZ7BHBX",
        "outputId": "8ff62adb-3c09-437f-9713-414fb2536225"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'infoseclab'...\n",
            "remote: Enumerating objects: 316, done.\u001b[K\n",
            "remote: Counting objects: 100% (35/35), done.\u001b[K\n",
            "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
            "remote: Total 316 (delta 11), reused 27 (delta 9), pack-reused 281\u001b[K\n",
            "Receiving objects: 100% (316/316), 64.87 MiB | 6.15 MiB/s, done.\n",
            "Resolving deltas: 100% (137/137), done.\n",
            "/content/infoseclab\n",
            "From https://github.com/ethz-privsec/infoseclab\n",
            " * branch            HEAD       -> FETCH_HEAD\n",
            "Already up to date.\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "\n",
        "# Download the lab files\n",
        "![ ! -d 'infoseclab' ] && git clone https://github.com/ethz-privsec/infoseclab.git\n",
        "%cd infoseclab\n",
        "!git pull https://github.com/ethz-privsec/infoseclab.git\n",
        "%cd ..\n",
        "if \"infoseclab\" not in sys.path:\n",
        "  sys.path.append(\"infoseclab\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UFYO94QBIKz"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qN2qQU8dBMG7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import infoseclab\n",
        "from infoseclab import extraction, Vocab, PREFIX\n",
        "\n",
        "from zipfile import ZipFile\n",
        "import numpy as np\n",
        "import os\n",
        "import json\n",
        "\n",
        "device = \"cuda\"\n",
        "\n",
        "# we won't need gradients here so let's disable them to make things faster\n",
        "torch.set_grad_enabled(False)\n",
        "\n",
        "# utilities for loading & saving results\n",
        "def read_results():\n",
        "  with open(os.path.join(RESULTS_PATH, \"extraction.json\"), \"r\") as f:\n",
        "    res = json.load(f)\n",
        "  return res\n",
        "\n",
        "\n",
        "def write_results(res):\n",
        "  assert len(res) == 4\n",
        "  assert type(res) == dict\n",
        "  with open(os.path.join(RESULTS_PATH, \"extraction.json\"), \"w\") as f:\n",
        "    res = json.dump(res, f)\n",
        "\n",
        "\n",
        "def print_results(res):\n",
        "  for key, value in res.items():\n",
        "    print(f\"{key.replace('_', ' ')}: {repr(value)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xYlh_fn7ETQ"
      },
      "source": [
        "#Create file to save results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmNr00RV7D4z",
        "outputId": "659a996b-9a99-47c3-d98d-d7ee77009f93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "main character: 'Sherlock Holmes'\n",
            "greedy guess: '3\\n an'\n",
            "greedy numeric guess: '39731'\n",
            "exact guess: '35192'\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "  res = read_results()\n",
        "  assert len(res) == 4\n",
        "  assert type(res) == dict\n",
        "except FileNotFoundError:\n",
        "  res = {\n",
        "      \"main_character\": None,\n",
        "      \"greedy_guess\": None,\n",
        "      \"greedy_numeric_guess\": None,\n",
        "      \"exact_guess\": None\n",
        "  }\n",
        "  write_results(res)\n",
        "\n",
        "print_results(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1PXWtQ-BnGm"
      },
      "source": [
        "#1.&nbsp;Freeform generation\n",
        "\n",
        "We will be working with a simple *character-level* language model.\n",
        "\n",
        "This is a model that takes as input a sentence (e.g., \"my name is \") and outputs a distribution over the next character in the sentence. We can then generate a character (e.g., \"F\") by sampling from this distribution. By applying the model recursively to its own output we can generate text character by character: \"my name is Florian\".\n",
        "\n",
        "Technically, the langauge model doesn't operate on `characters` but on `tokens` (numbers). The characters in the model's \"vocabulary\" are sorted, and can thus be referenced by an integer. The i-th value in the langauge model's output corresponds to the probability assigned to the i-th character in the vocabulary.\n",
        "\n",
        "You can find the full vocabulary (i.e., all characters that the language model can produce) in `infoseclab.extraction.Vocab`.\n",
        "This class has two utility dictionaries, `char_to_ix` and `ix_to_char` for converting from a character to its index (its token) and vice-versa:\n",
        "\n",
        "```\n",
        "Vocab.char_to_ix['a'] -> 54\n",
        "Vocab.ix_to_char[54] -> 'a'\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3z_zuKMQ37V1"
      },
      "outputs": [],
      "source": [
        "# load a simple character-level language model\n",
        "if not torch.cuda.is_available():\n",
        "  device = torch.device(\"cpu\")\n",
        "\n",
        "lm = extraction.load_lm(\"infoseclab/data/secret_model.pth\", device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qT7c-NI57MSX",
        "outputId": "841b4253-b26f-4f4b-c2ff-c4145cd3c6dd"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'hello world\\n with ensent for the new door awaiting him. Holmes passed himself\\n along his lodgings about a minis'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# example of how to generate text from the language model\n",
        "extraction.generate(lm, \"hello world\", length=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "c2SvdU1DDz7G",
        "outputId": "14be5fee-abba-4baa-92a4-dc39b355e561"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Manor Marter\\n James Aboyexlough Maspewall that of the London shot on a flush of violence\\n which we were on a conspicuous way if I saw Caripit Walls.\\n Good breakfast is Keeping at once agan, and passment is Unique.\\n Exactly, maide,\" he answered. \"The man we have for your missions at the place, are\\n refund of our only of the moment that I have seen him, having with fool and\\n original.\"\\n\\n \"What do you run you that the good?\"\\n\\n \"Dear more passive and your identity,\" she said.\\n \"He came a sonnog after earth this parsience it reported.\"\\n\\n My companion smiled. Holmes and \"Not on plays possibly not into\\n disclose.\"\\n\\n \"I said that he is a bloodsticac suffer of papers,\" said Holmes.\\n \"That had come to me is alone. Every thought is King and open he reason to which can be\\n promising to travell in a borias,\" said the matter as to the case doctor\\'s remarking.\\n It is conceivable, or is Hall of tired stop of his lips that they\\n lay in send and impatience us in it no one what is At British Garden.\\n Now you have a few captain\\'s providence burned upon our friend mind. I was\\n remarkable when the daily mother was importance roms together ever the\\n idea of it of his rough. The front of the pass easily need and see little directed\\n for my sights being an acquaintance of the account of the landlady.\\n It is a better by the even hall with the man at the cry. The delay\\n is arriving it against the figure, and it is possible as the front sign of my\\n hands, to spend me that I can gain listen to afford me and worthy by the afferciar\\n lad? Right, he knows the last rough tiber. He was Beins there to Manor Hous\\n serviced along the Brarish man whom the hundred hand was not in her near how fallia\\n and he return to his remark reason in the townshills up at a various rounded\\n open firm gaterness on Snat taken up. I looked under the more door.\"\\n\\n \"What was it placed him up, but I have three years of that. I had no doubt duning ring.\\n I passed and law short and associated the Powdword is Gardens. I saw that it\\n was new enough, and Sures. His naminate caught I should have saved\\n he was one of our aid with the wall made in sold it I can do myself. The\\n great powers white upon young Gardely. In a months were suspected of his head the\\n invention of the Sir Chacl is Victor Yardslaer Monday often and Adlone,\\n the instant was on some straight, with its words stylled; but\\n could hurried his hand and certainly when we had done. Holmes and Holmes swept\\n down his femight. He was laughing. London, have I ever remained money and the\\n forefing selfial. He had said it of the experidence. It is nearly equally\\n with us I saw on the whole matter was leaning to go in order.\\n Luck beside him to make his comrades face is a night and carried from at a\\n looking goespiery of man, which hurried of. His charge that his hands and\\n fast of straw triang in my eyes, which all suddenly which dashed past it destinite\\n them. Holmes gave to start across with one pistworther and bring\\n at the window study and for Sir Chairbah. It i'"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "extraction.generate(lm, \"Manor Marter\", length=3000)\n",
        "#Holmes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "lAC5yTuTCBJP",
        "outputId": "d42e8e5f-08ca-462b-b2aa-79740c50d763"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'record of the Manor\\n Opinion is Desmense on Scotland Yard, Watson Widings, his\\n household tin tissm. He was certainly possible that Mycroft for her, closed in\\n that talk belog would like to blow silent in the value. I dare sall before it, and\\n indignantiated the man in daouse when he was concerned.\"\\n\\n \"The emotional suspense is in the Paris. Let us think at this cause cheek and give you\\n the year 18585 horse fatal in the short save it. And never any peculiar vote.\\n Feor is Uslocks or must have seen a singular kenquary of\\n winter. I shall get a fog of originan pating name excited up, the near you will admit\\n you. But for the case you crime is Vanuary Belfan, which I gave the bright\\n uncertain Postnesd-flashing maleus to the outsies of course\\n herly aware to head for my dailing more retaining as long as is out. It\\n is impossible for you to close the morning.\"\\n\\n Holmes and Holmes rains he had passing remained to me that he had curbled as a\\n pension for him.\\n\\n \"That this papers.\"\\n\\n \"For the London! She had been getting out off to my applains.\"\\n\\n \"Do you see old Gennaro?\"\\n\\n \"I have come next combined theres during after dire is Kenning.\"\\n\\n \"Oh, the Colonel Saturday farther bad, then, I want to be very little men so\\n day. I should both do our enclosure of Mycroft. The dead man\\'s contents at\\n the Adding Cadonleton is Ux it thick upon you were sitting stretched and\\n garmed upon the matchment. We sharp evocial taking his walk on each order, sir,\\n are indeed it begins. My arguing our lips which limed us and put. I do not see the affair,\\n Watson, and cast him as one which was said to carry, and what do you go?\"\\n\\n \"I was carrying the top of the foreight. That, as to the queering, and\\n peering hnre this dead train and deed, but in you turned news to Can [: and the more cases\\n the hour so long for his death. Then he had reached this interview after a\\n carriage, for my breast upon this room might be far the door and the sister his apparrying\\n voice. He had inducated this closely houses. Might is Uvening\\n from the lodge. Collect. Don a passcream-neven sofa is 17. I could make it quite\\n malest through the plans being thighing. We wanted to password to him,\"\\n said he. \"I do not go to your pack, to Meistray. He is an engineond,\\n \"thing pain wish with ifresores, nearer. A ball, as Murdung\\n Road, who had a removed importance chosen brother, also by some mystery.\\n If there is no indication of the jungle which powers, all worthought, is essential\\n point is 4 and my rope and savages my door. He proved as Douglas I\\n like as a doing actually journey in our occasional fingers, but disappointed\\n the report. The \\'A.\\' The night is Unique, that Biryn\\'s open bottle\\n saw the course passion upon his train to clerge one of the assurants, but\\n Station had produced him followed. He observed the man of the whole\\n matter, had been of him. But it is indeed interprete horse by my sale out of the face.\\n The rass over a man, pointed to one of apart back, as we had been already out of\\n into a singular practi'"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "extraction.generate(lm, \"record of the Manor\", length=3000)\n",
        "#https://en.wikipedia.org/wiki/Mycroft_Holmes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "Oy17lCQmCaAv",
        "outputId": "01930430-b005-4587-beb2-52d76848f9fb"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Sherlock Holmes\\n Walter Holmes seem to have recovered the moment. Your passed used\\n stretched matter of the crime is K. V., to explain one. He is on it,\\n and best as your chokey is Urdio than decided. I was a only registence.\"\\n\\n \"Halloa, what are have you been by the Sko, who here are done to rest. A days the police\\n case, is regulant with him.\"\\n\\n My words had escaped with his hands into a long advance. Holmes lay was\\n concerned of revolvers and to call in the papers. His place was stright\\n a lonely claim examined. Now, a safe, thoughtful desertment as we\\n after a worst flash of hands, with one of his mind, and his hand the Mele,\\n stood in mind, and he caught him nor had caught the dark farthful intervonss\\n and throwing a dinner is mentioned and the door, he follows and\\n weak, with a flax to drank a suspicious other one brother Mycroft.\\n By the fog that was set upon lay half an attack in his words and a dark lonely words\\n energy as he all asked. If he was the portration, and the cries of the station\\n of James had sat deeply with his collaring oppussed balance in safe\\n thought had dark. There was some rock to shot than with him. The hutter run\\n and pointed, his papers, \"he took a trial! Keep that no sound was went in your father\\'s door at\\n Mawhar Camesclew\\'s get the last. You had sat saving upon a paper and\\n investigation from Way at by ten years ago, and it seems to laught at that with some\\n day. There is no notice upon this indications, Mr. Holmes, myself on the door were but\\n just as I had no plot?\"\\n\\n \"I was known with his life and sat to agreed he dropped a most inquirement of science at\\n the part of Setting Yord and worthy in our safe. There is a new body on my hand or\\n a most undismondle examples ago our first, which we have reason for it, and\\n calmed over an acquainting. I think that our fresh houses will not pass what he\\n was part by first instrument is Killy out and day. Something of what has not been\\n presuming. The laboration is Paris 341 Monday hand.\\n One long outsiotes your past days after what I was pressing look. She left\\n to any circle, since we should succeed and a planate thing. The men is Kenie, throw,\\n with door as the work on the dining-room for my crient. He showed thick\\n the warnings, and a gang, little weather, the arrest of Fuffle fired to placed the\\n iron a note step us and had been always slapped by an only way.\\n The terrible man had shaken when it was storily with a friend to end the assistance.\\n Mycroft he had subtled nine of the idea of what he had a thousand. I was\\n gently rest before me awes bank to Agent Official chin retreat.\\n Layl salence telling her and flashly at beiging in his key shaken from the older\\n in the famous room, with his overchations upon a brother.\\n Such friend eager angry not standing in this undoubted servant. Having cleaned at a\\n lossing, afrancial to save his thoughts. Possibly after his wife\\'s reason\\n to this: rather messenger broke away. This first company at pa seven cry of love\\n face with my life were old'"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "extraction.generate(lm, \"Sherlock Holmes\", length=3000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKL8VWwn4gVW"
      },
      "source": [
        "**This language model was trained on a collection of texts from a famous British book series. \n",
        "Your first goal is to figure out which books.**\n",
        "\n",
        "**Your guess should be in the form `\"Firstname Lastname\"` of the book series' main character.\n",
        "For example, if you guessed that the book series is Harry Potter, then your guess would be `\"Harry Potter\"`.**\n",
        "\n",
        "Note: the code immediately below doesn't check for correctness! It just checks that you've made a guess."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXRYQ3B6Bpti",
        "outputId": "23bf1536-a765-40ec-ed27-cd54800c1adc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "main character: 'Sherlock Holmes'\n",
            "greedy guess: '3\\n an'\n",
            "greedy numeric guess: '39737'\n",
            "exact guess: '35192'\n"
          ]
        }
      ],
      "source": [
        "guess = \"Sherlock Holmes\"\n",
        "res = read_results()\n",
        "res['main_character'] = guess\n",
        "write_results(res)\n",
        "print_results(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3c1YfON5bx9"
      },
      "source": [
        "#2.&nbsp;Secret extraction\n",
        "\n",
        "Unfortunately, the training data from this language model also contained the sentence `\"Florian's password is XXXXX\"`. (the real password is blanked out, your goal is to recover it!)\n",
        "\n",
        "The model might have *memorized* the correct password, and your goal will be to recover it.\n",
        "\n",
        "For this, you know the *prefix*: `\"Florian's password is \"`\n",
        "(you can find this stored under `infoseclab.extraction.PREFIX`).\n",
        "\n",
        "You also know that Florian's password is exactly 5 characters long (so that it it easier to memorize, *obviously*)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLR_DCUHDt5l"
      },
      "source": [
        "##2.1&nbsp; Greedy secret extraction\n",
        "\n",
        "You will first attempt to extract the secret password *greedily*, simply by sampling the **5 most likely characters**, one-by-one, from the language model, starting from the known `PREFIX`.\n",
        "\n",
        "You can use the `extraction.generate` method as inspiration for this.\n",
        "\n",
        "*Note that `extraction.generate` does <b>not</b> sample greedily from the model. Rather, it samples a character at random according to the probability distribution predicted by the model.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0-zAgLAEz-S",
        "outputId": "969cc1eb-abce-4d7e-a861-4a5e35c8c6a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Florian's password is \n",
            "22\n"
          ]
        }
      ],
      "source": [
        "print(infoseclab.extraction.PREFIX)\n",
        "print(len(infoseclab.extraction.PREFIX))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHLQ32NFg8pv",
        "outputId": "d6ba4f0b-5793-4934-ae37-5049720b8507"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'\\n' ' ' '!' '\"' '&' \"'\" '(' ')' '*' ',' '-' '.' '0' '1' '2' '3' '4' '5' '6' '7' '8' '9' ':' ';' '?' 'A' 'B' 'C' 'D' 'E' 'F' 'G' 'H' 'I' 'J' 'K' 'L' 'M' 'N' 'O' 'P' 'Q' 'R' 'S' 'T' 'U' 'V' 'W' 'X' 'Y' 'Z' '[' ']' '`' 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'k' 'l' 'm' 'n' 'o' 'p' 'q' 'r' 's' 't' 'u' 'v' 'w' 'x' 'y' 'z' '¢' '£' '¨' '©' 'ª' '®' '°' '±' '´' '¶' '»' '¼' '½' 'Â' 'Ã' 'â' 'Ÿ' '€' '™' "
          ]
        }
      ],
      "source": [
        "for i in range(99):\n",
        "  print(repr(Vocab.ix_to_char[i]), end=\" \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKbk-CesIzF0",
        "outputId": "1b8dcca9-5850-4203-b411-7b021618f33c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\"Florian's password is 33\\n\"\n",
            "\"Florian's password is 33\\n\"\n",
            "\"Florian's password is 33\\n\"\n",
            "\"Florian's password is 33\\n\"\n",
            "\"Florian's password is 33\\n\"\n",
            "\"Florian's password is 33'\"\n",
            "\"Florian's password is 33\\n\"\n",
            "\"Florian's password is 33\\n\"\n",
            "\"Florian's password is 33\\n\"\n",
            "\"Florian's password is 33\\n\"\n"
          ]
        }
      ],
      "source": [
        "for i in range(10):\n",
        "  print(repr(extraction.generate(lm, infoseclab.extraction.PREFIX + '33', length=1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "OQyQJM1DIelQ",
        "outputId": "6a7950c1-0d78-49d2-85d0-7cf53924d4d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "********************\n",
            "\"Florian's password is 3\\n an\"\n",
            "********************\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def test22():\n",
        "  _MAX_SAMPLING_ = 1000 #heuristicaly found by trying\n",
        "  _SECRET_ = infoseclab.extraction.PREFIX\n",
        "\n",
        "  _VERBOSE_22 = False\n",
        "\n",
        "  for i in range(5):\n",
        "    d = dict()\n",
        "    for j in range(_MAX_SAMPLING_):\n",
        "      temp = extraction.generate(lm, _SECRET_, length=1)\n",
        "      key = temp[-1]\n",
        "      if key in d:\n",
        "        d[key] = d[key] + 1\n",
        "      else:\n",
        "        d[key] = 0\n",
        "      if _VERBOSE_22:\n",
        "        print(repr(temp))\n",
        "    most_likely_char = max(d, key=d.get)\n",
        "    _SECRET_ = _SECRET_ + most_likely_char\n",
        "    if _VERBOSE_22:\n",
        "      print(20 * \"X\")\n",
        "      print(repr(most_likely_char))\n",
        "      # print(d[most_likely_char])\n",
        "      print(20 * \"X\")\n",
        "      print(20 * \"S\")\n",
        "      print(repr(_SECRET_))\n",
        "      print(20 * \"S\" + \"\\n\")\n",
        "\n",
        "  print(20 * \"*\")\n",
        "  print(repr(_SECRET_))\n",
        "  print(20 * \"*\")\n",
        "\n",
        "test22()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def test22_loss():\n",
        "  _MAX_SAMPLING_ = 1000 #heuristicaly found by trying\n",
        "  _SECRET_ = infoseclab.extraction.PREFIX\n",
        "\n",
        "  _VERBOSE_22 = False\n",
        "  for i in range(5):\n",
        "    d = dict()\n",
        "    for j in tqdm(range(_MAX_SAMPLING_), position=0, leave=True):\n",
        "      temp = extraction.generate(lm, _SECRET_, length=1)\n",
        "      key = temp[-1]\n",
        "      d[key] = float(extraction.get_loss(lm, temp))      \n",
        "      if _VERBOSE_22:\n",
        "        print(repr(temp))\n",
        "    most_likely_char = min(d, key=d.get)\n",
        "    _SECRET_ = _SECRET_ + most_likely_char\n",
        "    if _VERBOSE_22:\n",
        "      print(20 * \"X\")\n",
        "      print(repr(most_likely_char))\n",
        "      # print(d[most_likely_char])\n",
        "      print(20 * \"X\")\n",
        "      print(20 * \"S\")\n",
        "      print(repr(_SECRET_))\n",
        "      print(20 * \"S\" + \"\\n\")\n",
        "\n",
        "  print(20 * \"*\")\n",
        "  print(repr(_SECRET_))\n",
        "  print(20 * \"*\")\n",
        "\n",
        "test22_loss()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9jf6dR0xMsm",
        "outputId": "f881fb11-39b6-4b0d-a8f9-dd278edcf63f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [03:18<00:00,  5.05it/s]\n",
            "100%|██████████| 1000/1000 [03:28<00:00,  4.79it/s]\n",
            "100%|██████████| 1000/1000 [03:38<00:00,  4.57it/s]\n",
            "100%|██████████| 1000/1000 [03:44<00:00,  4.46it/s]\n",
            "100%|██████████| 1000/1000 [03:56<00:00,  4.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "\"Florian's password is 3\\n an\"\n",
            "********************\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tq-2nO8D0Z9",
        "outputId": "a132b64e-0a6c-486e-ba5a-3ce225e1e9d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:04<00:00, 227.74it/s]\n",
            "100%|██████████| 1000/1000 [00:03<00:00, 262.13it/s]\n",
            "100%|██████████| 1000/1000 [00:03<00:00, 259.62it/s]\n",
            "100%|██████████| 1000/1000 [00:04<00:00, 246.99it/s]\n",
            "100%|██████████| 1000/1000 [00:04<00:00, 240.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "\"Florian's password is 3\\n an\"\n",
            "********************\n",
            "greedy: Florian's password is '3\\n an'\n",
            "********************\n",
            "\n",
            "main character: 'Sherlock Holmes'\n",
            "greedy guess: '3\\n an'\n",
            "greedy numeric guess: '39737'\n",
            "exact guess: '35192'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def generate_greedy(lm, prompt, length=5):\n",
        "\n",
        "  _MAX_SAMPLING_ = 1000 #heuristicaly found by trying\n",
        "  _SECRET_ = infoseclab.extraction.PREFIX\n",
        "\n",
        "  _VERBOSE_22 = False\n",
        "  for i in range(5):\n",
        "    d = dict()\n",
        "    for j in tqdm(range(_MAX_SAMPLING_), position=0, leave=True):\n",
        "      temp = extraction.generate(lm, _SECRET_, length=1)\n",
        "      key = temp[-1]\n",
        "      d[key] = float(extraction.get_loss(lm, temp))      \n",
        "      if _VERBOSE_22:\n",
        "        print(repr(temp))\n",
        "    most_likely_char = min(d, key=d.get)\n",
        "    _SECRET_ = _SECRET_ + most_likely_char\n",
        "    if _VERBOSE_22:\n",
        "      print(20 * \"X\")\n",
        "      print(repr(most_likely_char))\n",
        "      # print(d[most_likely_char])\n",
        "      print(20 * \"X\")\n",
        "      print(20 * \"S\")\n",
        "      print(repr(_SECRET_))\n",
        "      print(20 * \"S\" + \"\\n\")\n",
        "\n",
        "  print(20 * \"*\")\n",
        "  print(repr(_SECRET_))\n",
        "  print(20 * \"*\")\n",
        "  return _SECRET_[-length:]\n",
        "\n",
        "guess_greedy = generate_greedy(lm, PREFIX, length=5) #best so far: '3\\n an', with 1000\n",
        "print(\"greedy:\", PREFIX + repr(guess_greedy))\n",
        "print(20 * \"*\" + \"\\n\")\n",
        "\n",
        "res = read_results()\n",
        "res['greedy_guess'] = guess_greedy\n",
        "write_results(res)\n",
        "print_results(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCtm2C2L5jep"
      },
      "source": [
        "##2.2&nbsp;Greedy numeric secret extraction\n",
        "\n",
        "Your greedy extraction likely generated some giberish! (but hey, a password might genuinely look like that).\n",
        "\n",
        "You are now given some extra information: **Florian's password only contains numbers!** (he's not very good at security).\n",
        "\n",
        "Modify your greedy sampling mechanism to repeatedly sample the 5 most likely *numbers*, one-by-one, starting from the known `PREFIX`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAaMjhunjrVG",
        "outputId": "bf2fee52-fab4-4fb3-8287-1c18fd4e71c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "********************\n",
            "\"Florian's password is 37253\"\n",
            "********************\n"
          ]
        }
      ],
      "source": [
        "import string\n",
        "\n",
        "def test23():\n",
        "  _MAX_SAMPLING_ = 50 #heuristicaly found by trying\n",
        "  _SECRET_ = infoseclab.extraction.PREFIX\n",
        "\n",
        "  _VERBOSE_23 = False\n",
        "\n",
        "  for i in range(5):\n",
        "    d = dict()\n",
        "    j = 0\n",
        "    while j < _MAX_SAMPLING_:\n",
        "      temp = extraction.generate(lm, _SECRET_, length=1)\n",
        "      key = temp[-1]\n",
        "      if not key.isdigit():\n",
        "        continue\n",
        "      if key in d:\n",
        "        d[key] = d[key] + 1\n",
        "      else:\n",
        "        d[key] = 0\n",
        "      if _VERBOSE_23:\n",
        "        print(repr(temp))\n",
        "      j += 1\n",
        "\n",
        "    most_likely_char = max(d, key=d.get)\n",
        "    _SECRET_ = _SECRET_ + most_likely_char\n",
        "    if _VERBOSE_23:\n",
        "      print(20 * \"X\")\n",
        "      print(repr(most_likely_char))\n",
        "      # print(d[most_likely_char])\n",
        "      print(20 * \"X\")\n",
        "      print(20 * \"S\")\n",
        "      print(repr(_SECRET_))\n",
        "      print(20 * \"S\" + \"\\n\")\n",
        "\n",
        "  print(20 * \"*\")\n",
        "  print(repr(_SECRET_))\n",
        "  print(20 * \"*\")\n",
        "\n",
        "test23()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def test23_loss():\n",
        "  _MAX_SAMPLING_ = 2000 #heuristicaly found by trying\n",
        "  _SECRET_ = infoseclab.extraction.PREFIX\n",
        "\n",
        "  _VERBOSE_23 = False\n",
        "  for i in range(5):\n",
        "    d = dict()\n",
        "    # j = 0\n",
        "    # while j < _MAX_SAMPLING_:\n",
        "    for j in tqdm(range(_MAX_SAMPLING_), position=0, leave=True):\n",
        "      temp = extraction.generate(lm, _SECRET_, length=1)\n",
        "      key = temp[-1]\n",
        "      if not key.isdigit():\n",
        "        continue\n",
        "      d[key] = float(extraction.get_loss(lm, temp)) \n",
        "      # j += 1     \n",
        "      if _VERBOSE_23:\n",
        "        print(repr(temp))\n",
        "\n",
        "    most_likely_char = min(d, key=d.get) #doesn't necessarily work since the dictionary could be empty\n",
        "    _SECRET_ = _SECRET_ + most_likely_char\n",
        "    if _VERBOSE_23:\n",
        "      print(20 * \"X\")\n",
        "      print(repr(most_likely_char))\n",
        "      # print(d[most_likely_char])\n",
        "      print(20 * \"X\")\n",
        "      print(20 * \"S\")\n",
        "      print(repr(_SECRET_))\n",
        "      print(20 * \"S\" + \"\\n\")\n",
        "\n",
        "  print(20 * \"*\")\n",
        "  print(repr(_SECRET_))\n",
        "  print(20 * \"*\")\n",
        "\n",
        "test23_loss()"
      ],
      "metadata": {
        "id": "ku8YQ2FtzNO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def test23_loss2():\n",
        "\n",
        "  _SECRET_ = infoseclab.extraction.PREFIX\n",
        "  _VERBOSE_23 = False\n",
        "\n",
        "  for i in tqdm(range(5)):\n",
        "    cur_loss = 1000\n",
        "    candidate_char = None\n",
        "    for j in range(10):\n",
        "      loss = float(extraction.get_loss(lm, _SECRET_ + str(j)))\n",
        "      if loss < cur_loss:\n",
        "        cur_loss = loss\n",
        "        candidate_char = str(j)\n",
        "        if _VERBOSE_23:\n",
        "          print(_SECRET_ + str(j) + \": \" + str(cur_loss))\n",
        "    _SECRET_ = _SECRET_ + candidate_char\n",
        "    if _VERBOSE_23:\n",
        "      print(repr(_SECRET_))\n",
        "\n",
        "  print()\n",
        "  print(20 * \"*\")\n",
        "  print(repr(_SECRET_))\n",
        "  print(20 * \"*\")\n",
        "\n",
        "test23_loss2()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PA0t92OeCA1e",
        "outputId": "e2cc3fa2-e041-4957-9889-81ffa07e63d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:05<00:00,  1.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "********************\n",
            "\"Florian's password is 39731\"\n",
            "********************\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Pbzx4dSa1sy",
        "outputId": "1edbcde5-7277-42a4-9fcb-1a32dc2f74e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:00<00:00, 42.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "\"Florian's password is 39731\"\n",
            "********************\n",
            "greedy (numeric): Florian's password is '39731'\n",
            "********************\n",
            "\n",
            "main character: 'Sherlock Holmes'\n",
            "greedy guess: '3\\n an'\n",
            "greedy numeric guess: '39731'\n",
            "exact guess: '35192'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import string\n",
        "\n",
        "def generate_greedy_numeric(lm, prompt, length=5):\n",
        "\n",
        "  _SECRET_ = prompt\n",
        "  _VERBOSE_23 = False\n",
        "\n",
        "  for i in tqdm(range(length)):\n",
        "    cur_loss = 1000\n",
        "    candidate_char = None\n",
        "    for j in range(10):\n",
        "      loss = float(extraction.get_loss(lm, _SECRET_ + str(j)))\n",
        "      if loss < cur_loss:\n",
        "        cur_loss = loss\n",
        "        candidate_char = str(j)\n",
        "        if _VERBOSE_23:\n",
        "          print(_SECRET_ + str(j) + \": \" + str(cur_loss))\n",
        "    _SECRET_ = _SECRET_ + candidate_char\n",
        "    if _VERBOSE_23:\n",
        "      print(repr(_SECRET_))\n",
        "    \n",
        "  print(20 * \"*\")\n",
        "  print(repr(_SECRET_))\n",
        "  print(20 * \"*\")\n",
        "\n",
        "  return _SECRET_[-length:]\n",
        "\n",
        "guess_greedy_numeric = generate_greedy_numeric(lm, PREFIX, length=5)\n",
        "print(\"greedy (numeric):\", PREFIX + repr(guess_greedy_numeric)) #best so far: 39731, with 30\n",
        "print(20 * \"*\" + \"\\n\")\n",
        "#best so far: 39731, with 30\n",
        "#best so far: 37333, with 42\n",
        "#best so far: 39737, with 50\n",
        "\n",
        "res = read_results()\n",
        "res['greedy_numeric_guess'] = guess_greedy_numeric\n",
        "write_results(res)\n",
        "print_results(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16tSQO1RHBxB"
      },
      "source": [
        "##2.3&nbsp;Exact numeric secret extraction\n",
        "\n",
        "Spoiler alert: the secret you found using greedy sampling is *not* Florian's password.\n",
        "\n",
        "As it turns out, sampling greedily from the model is not guaranteed to find the *sequence* of characters that is most likely according to the model's probability distribution.\n",
        "\n",
        "To illustrate, below you can compare the loss from your greedy guess, and a different (also incorrect) guess.</br>\n",
        "The guess `\"36175\"` has lower loss!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J5xuvMF7HFg9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30b80dc4-bea7-470f-db04-23af34f7ccf6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "39737 tensor(0.9848)\n",
            "36175 tensor(0.8980)\n"
          ]
        }
      ],
      "source": [
        "print(guess_greedy_numeric, extraction.get_loss(lm, PREFIX + guess_greedy_numeric))\n",
        "print(\"36175\", extraction.get_loss(lm, PREFIX + \"36175\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFh--BZnlO4W",
        "outputId": "1ac345d4-e9de-4894-b8c0-2e23456ef812"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36175 tensor(1.2504)\n",
            "39530 tensor(1.0724)\n",
            "36175 tensor(0.8980)\n",
            "32110 tensor(1.2880)\n",
            "39731 tensor(0.9791)\n",
            "37333 tensor(1.1196)\n",
            "39737 tensor(0.9848)\n"
          ]
        }
      ],
      "source": [
        "print(\"36175\", extraction.get_loss(lm, PREFIX + \"37253\"))\n",
        "print(\"39530\", extraction.get_loss(lm, PREFIX + \"39530\"))\n",
        "print(\"36175\", extraction.get_loss(lm, PREFIX + \"36175\"))\n",
        "print(\"32110\", extraction.get_loss(lm, PREFIX + \"32110\"))\n",
        "print(\"39731\", extraction.get_loss(lm, PREFIX + \"39731\"))\n",
        "print(\"37333\", extraction.get_loss(lm, PREFIX + \"37333\"))\n",
        "print(\"39737\", extraction.get_loss(lm, PREFIX + \"39737\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(float(extraction.get_loss(lm, PREFIX + \"39737\")))\n",
        "print(type(float(extraction.get_loss(lm, PREFIX + \"39737\"))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TcXFgQs0bxUK",
        "outputId": "4c770a97-9afc-49f4-fe56-e7575d792978"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9847548007965088\n",
            "<class 'float'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkmUuKQWbaVm"
      },
      "source": [
        "Now for the final part, find the 5-digit secret that actually *minimizes* the model's loss, when prompted with the `PREFIX`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VpTvxaVJuUoY"
      },
      "outputs": [],
      "source": [
        "def test24():\n",
        "  _MAX_SIZE_ = 12 #heuristicaly found by trying\n",
        "  _MAX_ITERATION_ = 10000 #heuristicaly found by trying\n",
        "  _SECRET_ = infoseclab.extraction.PREFIX\n",
        "\n",
        "  _VERBOSE_24 = True\n",
        "  password = \"\"\n",
        "  i = 0\n",
        "\n",
        "\n",
        "  d = dict()\n",
        "  if _VERBOSE_24:\n",
        "    print(d)\n",
        "  while len(d) < _MAX_SIZE_ and i < _MAX_ITERATION_:\n",
        "    temp = extraction.generate(lm, _SECRET_, length=5)\n",
        "    password = temp[-5:]\n",
        "    i += 1\n",
        "    if (i % 100) == 0 and _VERBOSE_24:\n",
        "      print(\"i: \", end=\"\")\n",
        "      print(i)\n",
        "    if not password.isdigit():\n",
        "      continue\n",
        "    d[password] = float(extraction.get_loss(lm, temp))\n",
        "    #if _VERBOSE_24:\n",
        "    print(d)\n",
        "\n",
        "  return d\n",
        "\n",
        "#attempt 1: {'35193': 0.5582603216171265, '35111': 0.7011959552764893, '35192': 0.5321089625358582, '35189': 0.695789098739624, '35589': 0.740381121635437, '35191': 0.6092814207077026}\n",
        "#attempt 2: {'35192': 0.5321089625358582, '35193': 0.5582603216171265, '35184': 0.7293773293495178, '35113': 0.6664919257164001, '35191': 0.6092814207077026, '35199': 0.6463838815689087, '38675': 1.0211955308914185, '35142': 0.8134702444076538}\n",
        "#attempt 3: {'35191': 0.6092814207077026, '35193': 0.5582603216171265, '35192': 0.5321089625358582, '35113': 0.6664919257164001, '35589': 0.740381121635437, '35199': 0.6463838815689087, '35196': 0.6920290589332581}\n",
        "#unique values found so far: 35193, 35111, 35192, 35189, 35589, 35191, 35184, 35113, 35199, 38675, 35142, 35196\n",
        "\n",
        "d = test24()\n",
        "print(d)\n",
        "min_loss_password = min(d, key=d.get)\n",
        "print(min_loss_password) #35192 is the winner with loss 0.5321089625358582"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cur_loss = 100\n",
        "for i in range(35190, 35200): #35192 - check last digit\n",
        "  loss = float(extraction.get_loss(lm, infoseclab.extraction.PREFIX + str(i)))\n",
        "  if loss < cur_loss: \n",
        "    cur_loss = loss\n",
        "    print(str(i) + \" : \", end=\"\")\n",
        "    print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJ7lkHdNqmwi",
        "outputId": "09791226-51ed-4eef-d29b-8ac74920f586"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35190 : 0.7972697615623474\n",
            "35191 : 0.6092814207077026\n",
            "35192 : 0.5321089625358582\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cur_loss = 100\n",
        "for i in range(35100, 35200): #35192 - check last 2 digit\n",
        "  loss = float(extraction.get_loss(lm, infoseclab.extraction.PREFIX + str(i)))\n",
        "  if loss < cur_loss: \n",
        "    cur_loss = loss\n",
        "    print(str(i) + \" : \", end=\"\")\n",
        "    print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJ8fUOJirQau",
        "outputId": "629f849d-855e-4654-f59c-d07d0161048b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35100 : 0.9929762482643127\n",
            "35110 : 0.8238042593002319\n",
            "35111 : 0.7011959552764893\n",
            "35112 : 0.695250928401947\n",
            "35113 : 0.6664919257164001\n",
            "35191 : 0.6092814207077026\n",
            "35192 : 0.5321089625358582\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cur_loss = 100\n",
        "for i in range(35000, 36000): #35192 - check last 3 digit\n",
        "  loss = float(extraction.get_loss(lm, infoseclab.extraction.PREFIX + str(i)))\n",
        "  if loss < cur_loss: \n",
        "    cur_loss = loss\n",
        "    print(str(i) + \" : \", end=\"\")\n",
        "    print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ho-bx3kgrU3o",
        "outputId": "37ce926d-ebcf-48c9-9c78-5acd05460248"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35000 : 2.0844781398773193\n",
            "35001 : 2.0481932163238525\n",
            "35100 : 0.9929762482643127\n",
            "35110 : 0.8238042593002319\n",
            "35111 : 0.7011959552764893\n",
            "35112 : 0.695250928401947\n",
            "35113 : 0.6664919257164001\n",
            "35191 : 0.6092814207077026\n",
            "35192 : 0.5321089625358582\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cur_loss = 100\n",
        "for i in range(30000, 40000): #35192 - check last 4 digit\n",
        "  loss = float(extraction.get_loss(lm, infoseclab.extraction.PREFIX + str(i)))\n",
        "  if loss < cur_loss: \n",
        "    cur_loss = loss\n",
        "    print(str(i) + \" : \", end=\"\")\n",
        "    print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rjiZU-qreDr",
        "outputId": "1e8d9df2-1338-4dc7-da8e-b09212401de8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30000 : 1.451418161392212\n",
            "30001 : 1.423754334449768\n",
            "30003 : 1.4088822603225708\n",
            "30010 : 1.311635136604309\n",
            "30011 : 1.2439020872116089\n",
            "30013 : 1.2317581176757812\n",
            "30052 : 1.1569525003433228\n",
            "30053 : 1.101498007774353\n",
            "30353 : 1.0866426229476929\n",
            "31110 : 1.04899263381958\n",
            "31111 : 0.9818975925445557\n",
            "31113 : 0.9711619019508362\n",
            "31122 : 0.9612119197845459\n",
            "31123 : 0.9164227843284607\n",
            "31133 : 0.91402268409729\n",
            "31513 : 0.9041312336921692\n",
            "31811 : 0.8704774379730225\n",
            "31813 : 0.8618948459625244\n",
            "31912 : 0.8086053133010864\n",
            "31913 : 0.7603574395179749\n",
            "35111 : 0.7011959552764893\n",
            "35112 : 0.695250928401947\n",
            "35113 : 0.6664919257164001\n",
            "35191 : 0.6092814207077026\n",
            "35192 : 0.5321089625358582\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CjLjFgyTIzgP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e60e4b1e-1477-4ef6-a84e-4bc1049a85b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{}\n",
            "{'35199': 0.6463836431503296}\n",
            "{'35199': 0.6463836431503296, '35191': 0.6092812418937683}\n",
            "{'35199': 0.6463836431503296, '35191': 0.6092812418937683, '35192': 0.5321088433265686}\n",
            "{'35199': 0.6463836431503296, '35191': 0.6092812418937683, '35192': 0.5321088433265686}\n",
            "{'35199': 0.6463836431503296, '35191': 0.6092812418937683, '35192': 0.5321088433265686}\n",
            "i: 1000\n",
            "{'35199': 0.6463836431503296, '35191': 0.6092812418937683, '35192': 0.5321088433265686, '35113': 0.6664920449256897}\n",
            "{'35199': 0.6463836431503296, '35191': 0.6092812418937683, '35192': 0.5321088433265686, '35113': 0.6664920449256897}\n",
            "{'35199': 0.6463836431503296, '35191': 0.6092812418937683, '35192': 0.5321088433265686, '35113': 0.6664920449256897, '35193': 0.5582602024078369}\n",
            "i: 2000\n",
            "{'35199': 0.6463836431503296, '35191': 0.6092812418937683, '35192': 0.5321088433265686, '35113': 0.6664920449256897, '35193': 0.5582602024078369}\n",
            "{'35199': 0.6463836431503296, '35191': 0.6092812418937683, '35192': 0.5321088433265686, '35113': 0.6664920449256897, '35193': 0.5582602024078369}\n",
            "{'35199': 0.6463836431503296, '35191': 0.6092812418937683, '35192': 0.5321088433265686, '35113': 0.6664920449256897, '35193': 0.5582602024078369}\n",
            "{'35199': 0.6463836431503296, '35191': 0.6092812418937683, '35192': 0.5321088433265686, '35113': 0.6664920449256897, '35193': 0.5582602024078369}\n",
            "{'35199': 0.6463836431503296, '35191': 0.6092812418937683, '35192': 0.5321088433265686, '35113': 0.6664920449256897, '35193': 0.5582602024078369, '35112': 0.6952511072158813}\n",
            "i: 3000\n",
            "{'35199': 0.6463836431503296, '35191': 0.6092812418937683, '35192': 0.5321088433265686, '35113': 0.6664920449256897, '35193': 0.5582602024078369, '35112': 0.6952511072158813}\n",
            "i: 4000\n",
            "{'35199': 0.6463836431503296, '35191': 0.6092812418937683, '35192': 0.5321088433265686, '35113': 0.6664920449256897, '35193': 0.5582602024078369, '35112': 0.6952511072158813}\n",
            "i: 5000\n",
            "{'35199': 0.6463836431503296, '35191': 0.6092812418937683, '35192': 0.5321088433265686, '35113': 0.6664920449256897, '35193': 0.5582602024078369, '35112': 0.6952511072158813}\n",
            "{'35199': 0.6463836431503296, '35191': 0.6092812418937683, '35192': 0.5321088433265686, '35113': 0.6664920449256897, '35193': 0.5582602024078369, '35112': 0.6952511072158813}\n",
            "{'35199': 0.6463836431503296, '35191': 0.6092812418937683, '35192': 0.5321088433265686, '35113': 0.6664920449256897, '35193': 0.5582602024078369, '35112': 0.6952511072158813, '35119': 0.7382231950759888}\n",
            "{'35199': 0.6463836431503296, '35191': 0.6092812418937683, '35192': 0.5321088433265686, '35113': 0.6664920449256897, '35193': 0.5582602024078369, '35112': 0.6952511072158813, '35119': 0.7382231950759888}\n",
            "{'35199': 0.6463836431503296, '35191': 0.6092812418937683, '35192': 0.5321088433265686, '35113': 0.6664920449256897, '35193': 0.5582602024078369, '35112': 0.6952511072158813, '35119': 0.7382231950759888}\n",
            "i: 6000\n",
            "{'35199': 0.6463836431503296, '35191': 0.6092812418937683, '35192': 0.5321088433265686, '35113': 0.6664920449256897, '35193': 0.5582602024078369, '35112': 0.6952511072158813, '35119': 0.7382231950759888}\n",
            "{'35199': 0.6463836431503296, '35191': 0.6092812418937683, '35192': 0.5321088433265686, '35113': 0.6664920449256897, '35193': 0.5582602024078369, '35112': 0.6952511072158813, '35119': 0.7382231950759888}\n",
            "i: 7000\n",
            "{'35199': 0.6463836431503296, '35191': 0.6092812418937683, '35192': 0.5321088433265686, '35113': 0.6664920449256897, '35193': 0.5582602024078369, '35112': 0.6952511072158813, '35119': 0.7382231950759888, '35183': 0.6892076730728149}\n",
            "{'35199': 0.6463836431503296, '35191': 0.6092812418937683, '35192': 0.5321088433265686, '35113': 0.6664920449256897, '35193': 0.5582602024078369, '35112': 0.6952511072158813, '35119': 0.7382231950759888, '35183': 0.6892076730728149}\n",
            "{'35199': 0.6463836431503296, '35191': 0.6092812418937683, '35192': 0.5321088433265686, '35113': 0.6664920449256897, '35193': 0.5582602024078369, '35112': 0.6952511072158813, '35119': 0.7382231950759888, '35183': 0.6892076730728149, '35186': 0.7502027750015259}\n",
            "i: 8000\n",
            "{'35199': 0.6463836431503296, '35191': 0.6092812418937683, '35192': 0.5321088433265686, '35113': 0.6664920449256897, '35193': 0.5582602024078369, '35112': 0.6952511072158813, '35119': 0.7382231950759888, '35183': 0.6892076730728149, '35186': 0.7502027750015259}\n",
            "{'35199': 0.6463836431503296, '35191': 0.6092812418937683, '35192': 0.5321088433265686, '35113': 0.6664920449256897, '35193': 0.5582602024078369, '35112': 0.6952511072158813, '35119': 0.7382231950759888, '35183': 0.6892076730728149, '35186': 0.7502027750015259}\n",
            "i: 9000\n",
            "{'35199': 0.6463836431503296, '35191': 0.6092812418937683, '35192': 0.5321088433265686, '35113': 0.6664920449256897, '35193': 0.5582602024078369, '35112': 0.6952511072158813, '35119': 0.7382231950759888, '35183': 0.6892076730728149, '35186': 0.7502027750015259}\n",
            "{'35199': 0.6463836431503296, '35191': 0.6092812418937683, '35192': 0.5321088433265686, '35113': 0.6664920449256897, '35193': 0.5582602024078369, '35112': 0.6952511072158813, '35119': 0.7382231950759888, '35183': 0.6892076730728149, '35186': 0.7502027750015259}\n",
            "{'35199': 0.6463836431503296, '35191': 0.6092812418937683, '35192': 0.5321088433265686, '35113': 0.6664920449256897, '35193': 0.5582602024078369, '35112': 0.6952511072158813, '35119': 0.7382231950759888, '35183': 0.6892076730728149, '35186': 0.7502027750015259}\n",
            "{'35199': 0.6463836431503296, '35191': 0.6092812418937683, '35192': 0.5321088433265686, '35113': 0.6664920449256897, '35193': 0.5582602024078369, '35112': 0.6952511072158813, '35119': 0.7382231950759888, '35183': 0.6892076730728149, '35186': 0.7502027750015259}\n",
            "{'35199': 0.6463836431503296, '35191': 0.6092812418937683, '35192': 0.5321088433265686, '35113': 0.6664920449256897, '35193': 0.5582602024078369, '35112': 0.6952511072158813, '35119': 0.7382231950759888, '35183': 0.6892076730728149, '35186': 0.7502027750015259}\n",
            "{'35199': 0.6463836431503296, '35191': 0.6092812418937683, '35192': 0.5321088433265686, '35113': 0.6664920449256897, '35193': 0.5582602024078369, '35112': 0.6952511072158813, '35119': 0.7382231950759888, '35183': 0.6892076730728149, '35186': 0.7502027750015259}\n",
            "i: 10000\n",
            "********************\n",
            "{'35199': 0.6463836431503296, '35191': 0.6092812418937683, '35192': 0.5321088433265686, '35113': 0.6664920449256897, '35193': 0.5582602024078369, '35112': 0.6952511072158813, '35119': 0.7382231950759888, '35183': 0.6892076730728149, '35186': 0.7502027750015259}\n",
            "********************\n",
            "35192\n",
            "********************\n",
            "\n",
            "exact: Florian's password is '35192'\n",
            "main character: 'Sherlock Holmes'\n",
            "greedy guess: '3\\n an'\n",
            "greedy numeric guess: '39731'\n",
            "exact guess: '35192'\n"
          ]
        }
      ],
      "source": [
        "def generate_exact(lm, prompt, length=5):\n",
        "  _MAX_SIZE_ = 12 #heuristicaly found by trying\n",
        "  _MAX_ITERATION_ = 10000 #heuristicaly found by trying\n",
        "  _SECRET_ = prompt\n",
        "\n",
        "  _VERBOSE_24 = True\n",
        "  password = \"\"\n",
        "  i = 0\n",
        "\n",
        "\n",
        "  d = dict()\n",
        "  if _VERBOSE_24:\n",
        "    print(d)\n",
        "  while len(d) < _MAX_SIZE_ and i < _MAX_ITERATION_:\n",
        "    temp = extraction.generate(lm, _SECRET_, length=5)\n",
        "    password = temp[-5:]\n",
        "    i += 1\n",
        "    if (i % 1000) == 0 and _VERBOSE_24:\n",
        "      print(\"i: \", end=\"\")\n",
        "      print(i)\n",
        "    if not password.isdigit():\n",
        "      continue\n",
        "    d[password] = float(extraction.get_loss(lm, temp))\n",
        "    #if _VERBOSE_24:\n",
        "    print(d)\n",
        "\n",
        "  print(20 * \"*\")\n",
        "  print(d)\n",
        "  print(20 * \"*\")\n",
        "  min_loss_password = min(d, key=d.get)\n",
        "  print(min_loss_password) #35192 is the winner with loss 0.5321089625358582\n",
        "  print(20 * \"*\")\n",
        "  return min_loss_password\n",
        "\n",
        "guess_exact = generate_exact(lm, PREFIX, length=5)\n",
        "print(\"\\nexact:\", PREFIX + repr(guess_exact))\n",
        "\n",
        "res = read_results()\n",
        "res['exact_guess'] = guess_exact\n",
        "write_results(res)\n",
        "print_results(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNMIfOoL_dOt"
      },
      "source": [
        "# Create submission file (**upload `results.zip` to moodle**) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0N1Uv1Y_cLk",
        "outputId": "c0bd2ff2-2c20-4c59-d122-3802a576f1dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "updating: extraction.json (deflated 25%)\n",
            "updating: x_adv_targeted.npy (deflated 10%)\n",
            "updating: x_adv_detect.npy (deflated 10%)\n",
            "updating: x_adv_random.npy (deflated 10%)\n"
          ]
        }
      ],
      "source": [
        "!zip -j -r \"{RESULTS_PATH}/results.zip\" {RESULTS_PATH} --exclude \"*x_adv_untargeted.npy\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "VSPUajuP_zcd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "062982a0-96e9-4962-aefc-c564c00bb2b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "main character: 'Sherlock Holmes'\n",
            "greedy guess: '3\\n an'\n",
            "greedy numeric guess: '39731'\n",
            "exact guess: '35192'\n"
          ]
        }
      ],
      "source": [
        "with ZipFile(f\"{RESULTS_PATH}/results.zip\", 'r') as zip:\n",
        "    res = json.load(zip.open(\"extraction.json\"))\n",
        "    print_results(res)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}